# Guia Completo: Redes Neurais Convolucionais (CNN)

> [!info] Introdu√ß√£o As **Convolutional Neural Networks (CNNs)** s√£o um tipo especializado de rede neural artificial especialmente eficaz para processamento de dados que possuem estrutura em grade, como **imagens**. Elas revolucionaram √°reas como vis√£o computacional, reconhecimento de imagem e processamento de v√≠deo.

---

## üß† O que s√£o CNNs?

> [!abstract] Conceito Base CNNs s√£o **inspiradas pelo c√≥rtex visual** dos mam√≠feros. Elas conseguem **detectar padr√µes locais** em imagens atrav√©s de opera√ß√µes matem√°ticas chamadas **convolu√ß√µes**, preservando as rela√ß√µes espaciais entre pixels.

### Por que CNNs s√£o Superiores para Imagens?

|Problema das Redes Densas|Solu√ß√£o das CNNs|
|---|---|
|**Muitos par√¢metros**: Uma imagem 224x224x3 = 150k neur√¥nios|**Compartilhamento de par√¢metros**: Filtros reutilizados|
|**Perda da informa√ß√£o espacial**: Pixels s√£o "achatados"|**Preserva√ß√£o espacial**: Mant√©m vizinhan√ßa|
|**N√£o invariante a transla√ß√£o**: Mesmo objeto em posi√ß√£o diferente|**Invari√¢ncia**: Detecta padr√µes independente da posi√ß√£o|

---

## üîß Componentes Fundamentais

### 1. **Convolu√ß√£o (Convolution)**

> [!note] Opera√ß√£o Matem√°tica Core A **convolu√ß√£o** √© uma opera√ß√£o matem√°tica que combina duas fun√ß√µes para produzir uma terceira. Em CNNs, aplicamos um **filtro (kernel)** sobre uma **imagem** para detectar caracter√≠sticas espec√≠ficas.

#### F√≥rmula da Convolu√ß√£o 2D

$$
(I * K)(i,j) = ‚àë‚àë I(i+m, j+n) √ó K(m,n)
               m n
$$

Onde:

- **I**: Imagem de entrada
- **K**: Kernel (filtro)
- **(i,j)**: Posi√ß√£o na imagem resultante

#### Exemplo Visual da Convolu√ß√£o

> [!example] Detec√ß√£o de Bordas Verticais **Imagem 6x6:**
> 
> ```
> 3 0 1 2 7 4
> 1 5 8 9 3 1
> 2 7 2 5 1 4
> 0 1 3 1 7 8
> 4 2 1 6 2 8
> 2 3 2 1 2 3
> ```
> 
> **Filtro 3x3 (Sobel Vertical):**
> 
> ```
> -1  0  1
> -1  0  1
> -1  0  1
> ```
> 
> **Resultado da Convolu√ß√£o:**
> 
> ```
>  4  -5  -2   8
>  2  -3  -2   3
> -3  -1   4   6
>  4   2   2   4
> ```

### 2. **Kernels/Filtros**

> [!important] Detectores de Caracter√≠sticas **Kernels** s√£o pequenas matrizes (geralmente 3x3, 5x5, 7x7) que detectam caracter√≠sticas espec√≠ficas como bordas, texturas e formas.

#### Tipos Comuns de Filtros

|Filtro|Matriz 3x3|Fun√ß√£o|
|---|---|---|
|**Sobel X**|`[[-1,0,1],[-2,0,2],[-1,0,1]]`|Detecta bordas horizontais|
|**Sobel Y**|`[[-1,-2,-1],[0,0,0],[1,2,1]]`|Detecta bordas verticais|
|**Gaussian Blur**|`[[1,2,1],[2,4,2],[1,2,1]]/16`|Suaviza√ß√£o|
|**Sharpen**|`[[0,-1,0],[-1,5,-1],[0,-1,0]]`|Acentua detalhes|
|**Edge Detection**|`[[-1,-1,-1],[-1,8,-1],[-1,-1,-1]]`|Detecta todas as bordas|

> [!tip] Aprendizado Autom√°tico Em CNNs, os **valores dos kernels s√£o aprendidos automaticamente** durante o treinamento, n√£o programados manualmente!

### 3. **Camadas Convolucionais (Convolutional Layers)**

> [!abstract] Estrutura B√°sica As **camadas convolucionais** aplicam m√∫ltiplos filtros na imagem de entrada, produzindo **mapas de caracter√≠sticas (feature maps)** que destacam diferentes aspectos da imagem.

#### Par√¢metros Importantes

##### **Padding**

- **Same Padding**: Adiciona zeros nas bordas para manter o tamanho
- **Valid Padding**: N√£o adiciona padding, reduz o tamanho

```
Sem Padding (Valid):  Entrada 5x5 ‚Üí Sa√≠da 3x3 (com kernel 3x3)
Com Padding (Same):   Entrada 5x5 ‚Üí Sa√≠da 5x5 (com kernel 3x3)
```

##### **Stride**

- **Stride 1**: Move o filtro pixel por pixel
- **Stride 2**: Move o filtro de 2 em 2 pixels

```
Stride 1: Entrada 7x7 ‚Üí Sa√≠da 5x5 (kernel 3x3)
Stride 2: Entrada 7x7 ‚Üí Sa√≠da 3x3 (kernel 3x3)
```

#### C√°lculo do Tamanho de Sa√≠da

```
Tamanho_Sa√≠da = (Entrada + 2√óPadding - Kernel) / Stride + 1
```

> [!example] Exemplo Pr√°tico **Entrada**: 32x32, **Kernel**: 5x5, **Padding**: 2, **Stride**: 1
> 
> **C√°lculo**: $(32 + 2√ó2 - 5) / 1 + 1 = 32$
> 
> **Resultado**: Sa√≠da 32x32 (mesmo tamanho da entrada)

### 4. **Camadas de Pooling**

> [!note] Redu√ß√£o Dimensional **Pooling** reduz o tamanho espacial dos mapas de caracter√≠sticas, diminuindo par√¢metros e evitando overfitting.

#### Tipos de Pooling

##### **Max Pooling**

Pega o **valor m√°ximo** em cada regi√£o:

```
Entrada 4x4:          Max Pooling 2x2:
1  3  2  4            ‚Üí    3  4
2  9  1  1                 8  3
1  8  7  3
0  2  4  1
```

##### **Average Pooling**

Calcula a **m√©dia** em cada regi√£o:

```
Entrada 4x4:          Avg Pooling 2x2:
4  2  1  3            ‚Üí    3.75  2
1  6  3  2                 2.75  3
2  4  1  4
1  1  6  2
```

> [!success] Benef√≠cios do Pooling
> 
> - **Reduz overfitting**: Menos par√¢metros para aprender
> - **Invari√¢ncia posicional**: Pequenas transla√ß√µes n√£o afetam resultado
> - **Reduz custo computacional**: Menos dados para processar
> - **Aumenta campo receptivo**: Cada neur√¥nio "v√™" √°rea maior da imagem original

### 5. **Fun√ß√£o de Ativa√ß√£o**

> [!important] N√£o-Linearidade Fun√ß√µes de ativa√ß√£o introduzem **n√£o-linearidade** na rede, permitindo que ela aprenda padr√µes complexos.

#### **ReLU (Rectified Linear Unit)** - Mais Comum

```python
ReLU(x) = max(0, x)
```

**Vantagens:**

- Simples de calcular
- Evita problema do gradiente desvanescente
- Esparsidade natural (muitos zeros)

#### **Outras Ativa√ß√µes**

- **Leaky ReLU**: `f(x) = max(0.01x, x)`
- **ELU**: Exponential Linear Unit
- **Swish**: `f(x) = x √ó sigmoid(x)`

---

## üèóÔ∏è Arquitetura T√≠pica de uma CNN

> [!abstract] Estrutura em Blocos Uma CNN t√≠pica combina camadas de diferentes tipos em uma arquitetura hier√°rquica:

```mermaid
graph LR
    A[Imagem de Entrada<br/>224x224x3] --> B[Conv Layer 1<br/>64 filtros 3x3]
    B --> C[ReLU]
    C --> D[Conv Layer 2<br/>64 filtros 3x3]
    D --> E[ReLU]
    E --> F[Max Pool<br/>2x2]
    F --> G[Conv Layer 3<br/>128 filtros 3x3]
    G --> H[ReLU]
    H --> I[Max Pool<br/>2x2]
    I --> J[Flatten]
    J --> K[Dense Layer<br/>512 neur√¥nios]
    K --> L[ReLU]
    L --> M[Dense Layer<br/>10 classes]
    M --> N[Softmax]
    
    style A fill:#e1f5fe
    style F fill:#fff3e0
    style I fill:#fff3e0
    style J fill:#f3e5f5
    style N fill:#e8f5e8
```

### Evolu√ß√£o das Dimens√µes

|Camada|Entrada|Sa√≠da|Par√¢metros|
|---|---|---|---|
|**Input**|-|224√ó224√ó3|0|
|**Conv1**|224√ó224√ó3|224√ó224√ó64|1,792|
|**Pool1**|224√ó224√ó64|112√ó112√ó64|0|
|**Conv2**|112√ó112√ó64|112√ó112√ó128|73,856|
|**Pool2**|112√ó112√ó128|56√ó56√ó128|0|
|**Flatten**|56√ó56√ó128|401,408|0|
|**Dense**|401,408|512|205,521,408|
|**Output**|512|10|5,130|

---

## üíª Exemplo Pr√°tico: CNN para Classifica√ß√£o de D√≠gitos

### Implementa√ß√£o Completa em Python

```python
import tensorflow as tf
from tensorflow.keras import layers, models
import numpy as np
import matplotlib.pyplot as plt

# ============================================================================
# 1. PREPARA√á√ÉO DOS DADOS
# ============================================================================

# Carrega dataset MNIST (d√≠gitos escritos √† m√£o)
(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()

print(f"Shape dos dados de treino: {x_train.shape}")
print(f"Shape das labels de treino: {y_train.shape}")
print(f"Shape dos dados de teste: {x_test.shape}")

# Normaliza os pixels para [0, 1]
x_train = x_train.astype('float32') / 255.0
x_test = x_test.astype('float32') / 255.0

# Adiciona dimens√£o de canal (28, 28) -> (28, 28, 1)
x_train = x_train[..., tf.newaxis]
x_test = x_test[..., tf.newaxis]

print(f"Shape ap√≥s reshape: {x_train.shape}")

# ============================================================================
# 2. CONSTRU√á√ÉO DA CNN
# ============================================================================

def criar_cnn_modelo():
    """
    Cria uma CNN simples para classifica√ß√£o de d√≠gitos MNIST
    """
    model = models.Sequential([
        # Primeira camada convolucional
        layers.Conv2D(filters=32,           # 32 filtros diferentes
                     kernel_size=(3, 3),    # Kernels 3x3
                     activation='relu',     # Fun√ß√£o de ativa√ß√£o ReLU
                     input_shape=(28, 28, 1)),  # Entrada: 28x28x1
        
        # Primeira camada de pooling
        layers.MaxPooling2D(pool_size=(2, 2)),  # Reduz para metade
        
        # Segunda camada convolucional
        layers.Conv2D(filters=64,           # 64 filtros
                     kernel_size=(3, 3),    # Kernels 3x3
                     activation='relu'),
        
        # Segunda camada de pooling
        layers.MaxPooling2D(pool_size=(2, 2)),
        
        # Terceira camada convolucional
        layers.Conv2D(filters=64,
                     kernel_size=(3, 3),
                     activation='relu'),
        
        # Achata para conectar com camadas densas
        layers.Flatten(),
        
        # Camada densa (fully connected)
        layers.Dense(64, activation='relu'),
        
        # Camada de sa√≠da (10 classes para d√≠gitos 0-9)
        layers.Dense(10, activation='softmax')  # Softmax para probabilidades
    ])
    
    return model

# Cria o modelo
modelo = criar_cnn_modelo()

# Mostra arquitetura do modelo
modelo.summary()

# ============================================================================
# 3. COMPILA√á√ÉO E TREINAMENTO
# ============================================================================

# Compila o modelo
modelo.compile(
    optimizer='adam',                    # Otimizador Adam
    loss='sparse_categorical_crossentropy',  # Loss para classifica√ß√£o
    metrics=['accuracy']                 # M√©trica de acur√°cia
)

print("Iniciando treinamento...")

# Treina o modelo
history = modelo.fit(
    x_train, y_train,
    epochs=5,                    # 5 √©pocas de treinamento
    batch_size=32,               # 32 amostras por batch
    validation_split=0.2,        # 20% para valida√ß√£o
    verbose=1                    # Mostra progresso
)

# ============================================================================
# 4. AVALIA√á√ÉO
# ============================================================================

# Avalia no conjunto de teste
test_loss, test_accuracy = modelo.evaluate(x_test, y_test, verbose=0)
print(f"\nAcur√°cia no teste: {test_accuracy:.4f}")
print(f"Loss no teste: {test_loss:.4f}")

# ============================================================================
# 5. VISUALIZA√á√ÉO DOS RESULTADOS
# ============================================================================

def plot_training_history(history):
    """Plota hist√≥rico de treinamento"""
    
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))
    
    # Acur√°cia
    ax1.plot(history.history['accuracy'], label='Treino', color='blue')
    ax1.plot(history.history['val_accuracy'], label='Valida√ß√£o', color='red')
    ax1.set_title('Acur√°cia do Modelo')
    ax1.set_xlabel('√âpoca')
    ax1.set_ylabel('Acur√°cia')
    ax1.legend()
    ax1.grid(True)
    
    # Loss
    ax2.plot(history.history['loss'], label='Treino', color='blue')
    ax2.plot(history.history['val_loss'], label='Valida√ß√£o', color='red')
    ax2.set_title('Loss do Modelo')
    ax2.set_xlabel('√âpoca')
    ax2.set_ylabel('Loss')
    ax2.legend()
    ax2.grid(True)
    
    plt.tight_layout()
    plt.show()

# Plota hist√≥rico
plot_training_history(history)

# ============================================================================
# 6. TESTANDO COM EXEMPLOS
# ============================================================================

def testar_predicoes(modelo, x_test, y_test, num_exemplos=10):
    """Testa predi√ß√µes em exemplos aleat√≥rios"""
    
    # Seleciona exemplos aleat√≥rios
    indices = np.random.choice(len(x_test), num_exemplos, replace=False)
    
    # Faz predi√ß√µes
    predicoes = modelo.predict(x_test[indices])
    predicoes_classes = np.argmax(predicoes, axis=1)
    
    # Visualiza resultados
    fig, axes = plt.subplots(2, 5, figsize=(15, 6))
    axes = axes.ravel()
    
    for i, idx in enumerate(indices):
        # Mostra imagem
        axes[i].imshow(x_test[idx].squeeze(), cmap='gray')
        axes[i].set_title(f'Real: {y_test[idx]}\nPredi√ß√£o: {predicoes_classes[i]}\n'
                         f'Confian√ßa: {np.max(predicoes[i]):.2f}')
        axes[i].axis('off')
        
        # Colore borda baseado na predi√ß√£o
        if predicoes_classes[i] == y_test[idx]:
            axes[i].patch.set_edgecolor('green')  # Correto
        else:
            axes[i].patch.set_edgecolor('red')    # Incorreto
        axes[i].patch.set_linewidth(3)
    
    plt.tight_layout()
    plt.show()

# Testa predi√ß√µes
testar_predicoes(modelo, x_test, y_test)

# ============================================================================
# 7. VISUALIZA√á√ÉO DOS FILTROS APRENDIDOS
# ============================================================================

def visualizar_filtros(modelo, camada=0):
    """Visualiza os filtros aprendidos na primeira camada convolucional"""
    
    # Extrai pesos da primeira camada convolucional
    filters = modelo.layers[camada].get_weights()[0]
    
    print(f"Shape dos filtros: {filters.shape}")
    
    # Normaliza filtros para visualiza√ß√£o
    f_min, f_max = filters.min(), filters.max()
    filters = (filters - f_min) / (f_max - f_min)
    
    # Plota primeiros 16 filtros
    n_filters = min(16, filters.shape[-1])
    fig, axes = plt.subplots(4, 4, figsize=(12, 12))
    axes = axes.ravel()
    
    for i in range(n_filters):
        axes[i].imshow(filters[:, :, 0, i], cmap='viridis')
        axes[i].set_title(f'Filtro {i+1}')
        axes[i].axis('off')
    
    plt.suptitle('Filtros Aprendidos na Primeira Camada Convolucional', 
                 fontsize=16)
    plt.tight_layout()
    plt.show()

# Visualiza filtros
visualizar_filtros(modelo)

# ============================================================================
# 8. AN√ÅLISE DE FEATURE MAPS
# ============================================================================

def visualizar_feature_maps(modelo, x_test, indice=0):
    """Visualiza os feature maps de uma imagem espec√≠fica"""
    
    # Seleciona uma imagem
    img = x_test[indice:indice+1]
    
    # Cria modelo para extrair feature maps
    layer_outputs = [layer.output for layer in modelo.layers[:4]]  # Primeiras 4 camadas
    activation_model = models.Model(inputs=modelo.input, outputs=layer_outputs)
    
    # Obt√©m ativa√ß√µes
    activations = activation_model.predict(img)
    
    layer_names = ['Conv2D_1', 'MaxPool_1', 'Conv2D_2', 'MaxPool_2']
    
    for layer_name, activation in zip(layer_names, activations):
        if len(activation.shape) == 4:  # Camadas convolucionais
            n_features = min(8, activation.shape[-1])  # Mostra at√© 8 mapas
            
            fig, axes = plt.subplots(2, 4, figsize=(16, 8))
            axes = axes.ravel()
            
            for i in range(n_features):
                axes[i].imshow(activation[0, :, :, i], cmap='viridis')
                axes[i].set_title(f'Feature Map {i+1}')
                axes[i].axis('off')
            
            # Remove eixos extras
            for i in range(n_features, 8):
                axes[i].axis('off')
                
            plt.suptitle(f'Feature Maps - {layer_name}', fontsize=16)
            plt.tight_layout()
            plt.show()

# Visualiza feature maps
print("Visualizando feature maps...")
visualizar_feature_maps(modelo, x_test, indice=0)

print("\n" + "="*60)
print("AN√ÅLISE COMPLETA DA CNN FINALIZADA!")
print("="*60)
```

---

## üìä Arquiteturas CNN Famosas

> [!example] Marcos Hist√≥ricos Algumas arquiteturas revolucionaram o campo de vis√£o computacional:

### **[[LeNet-5]] (1998)**

- **Prop√≥sito**: Reconhecimento de d√≠gitos
- **Estrutura**: 2 Conv + 2 FC
- **Tamanho**: ~60k par√¢metros

### **[[AlexNet]] (2012)**

- **Revolu√ß√£o**: Primeira CNN a vencer ImageNet
- **Inova√ß√µes**: ReLU, Dropout, GPU training
- **Tamanho**: ~60M par√¢metros

### **[[VGGNet]] (2014)**

- **Caracter√≠sticas**: Filtros 3x3, arquitetura profunda
- **Variantes**: VGG-16, VGG-19
- **Tamanho**: ~138M par√¢metros

### **[[ResNet]] (2015)**

- **Inova√ß√£o**: Conex√µes residuais (skip connections)
- **Profundidade**: At√© 152 camadas
- **Problema resolvido**: Degrada√ß√£o em redes muito profundas

### **[[EfficientNet]] (2019)**

- **Abordagem**: Scaling balanceado (largura, profundidade, resolu√ß√£o)
- **Efici√™ncia**: Melhor acur√°cia com menos par√¢metros

---

## üéØ Aplica√ß√µes Pr√°ticas das CNNs

### **Vis√£o Computacional**

- ‚úÖ **Classifica√ß√£o de imagens**: Identificar objetos em fotos
- ‚úÖ **Detec√ß√£o de objetos**: Localizar e classificar m√∫ltiplos objetos
- ‚úÖ **Segmenta√ß√£o**: Identificar pixels pertencentes a cada objeto
- ‚úÖ **Reconhecimento facial**: Identifica√ß√£o e verifica√ß√£o de pessoas

### **Medicina**

- üè• **Diagn√≥stico por imagem**: Raio-X, tomografias, resson√¢ncias
- üè• **Detec√ß√£o de c√¢ncer**: An√°lise de bi√≥psias e exames
- üè• **An√°lise de retina**: Detec√ß√£o de doen√ßas oculares

### **Carros Aut√¥nomos**

- üöó **Detec√ß√£o de pedestres**: Seguran√ßa em tempo real
- üöó **Reconhecimento de sinais**: Placas de tr√¢nsito
- üöó **Segmenta√ß√£o de pista**: Identifica√ß√£o da estrada

### **Arte e Criatividade**

- üé® **Style Transfer**: Aplicar estilo art√≠stico a fotos
- üé® **Gera√ß√£o de imagens**: GANs para criar arte artificial
- üé® **Super-resolu√ß√£o**: Aumentar qualidade de imagens

---

## ‚ö° Dicas e Melhores Pr√°ticas

### **Prepara√ß√£o de Dados**

> [!tip] Qualidade dos Dados
> 
> - **Normaliza√ß√£o**: Sempre normalize pixels para [0,1] ou [-1,1]
> - **Data Augmentation**: Rota√ß√£o, zoom, flip para aumentar dataset
> - **Balanceamento**: Garanta classes equilibradas
> - **Valida√ß√£o**: Sempre separe dados de treino/valida√ß√£o/teste

### **Arquitetura**

> [!success] Design Eficiente
> 
> - **Comece simples**: Poucas camadas, depois aumente complexidade
> - **Batch Normalization**: Acelera treinamento e melhora estabilidade
> - **Dropout**: Evita overfitting em camadas densas
> - **Skip Connections**: Para redes muito profundas (ResNet style)

### **Treinamento**

> [!important] Otimiza√ß√£o
> 
> - **Learning Rate**: Comece com 0.001 (Adam) ou 0.01 (SGD)
> - **Early Stopping**: Pare se valida√ß√£o n√£o melhora
> - **Learning Rate Decay**: Reduza gradualmente durante treino
> - **Checkpoints**: Salve melhor modelo durante treinamento

### **Debugging**

> [!warning] Problemas Comuns
> 
> - **Overfitting**: Loss de treino ‚â™ loss de valida√ß√£o
>     - _Solu√ß√£o_: Mais dados, dropout, regulariza√ß√£o
> - **Underfitting**: Ambos os losses altos
>     - _Solu√ß√£o_: Modelo mais complexo, menos regulariza√ß√£o
> - **Gradiente explodindo**: Loss vira NaN
>     - _Solu√ß√£o_: Learning rate menor, gradient clipping

---

## üî¨ Matem√°tica por Tr√°s das CNNs

### **Backpropagation em CNNs**

> [!note] Gradientes nas Convolu√ß√µes Durante o treinamento, os gradientes s√£o propagados atrav√©s das camadas convolucionais usando a regra da cadeia:

```
‚àÇL/‚àÇw = ‚àÇL/‚àÇy ‚äó x
‚àÇL/‚àÇx = w_rotated ‚äó ‚àÇL/‚àÇy
```

Onde:

- **L**: Loss function
- **w**: Pesos do kernel
- **x**: Entrada da camada
- **y**: Sa√≠da da camada
- **‚äó**: Opera√ß√£o de convolu√ß√£o

### **C√°lculo de Par√¢metros**

Para uma camada convolucional:

```
Par√¢metros = (kernel_height √ó kernel_width √ó input_channels + 1) √ó output_channels
```

> [!example] Exemplo **Entrada**: 224√ó224√ó3, **Filtros**: 64 de 3√ó3
> 
> **C√°lculo**: (3 √ó 3 √ó 3 + 1) √ó 64 = 1,792 par√¢metros

---

## üìö Resumo e Conclus√µes

> [!success] Pontos-Chave das CNNs
> 
> 1. **Convolu√ß√µes** detectam caracter√≠sticas locais usando filtros aprendidos
> 2. **Pooling** reduz dimensionalidade e adiciona invari√¢ncia
> 3. **Hierarquia** permite detec√ß√£o de padr√µes simples ‚Üí complexos
> 4. **Compartilhamento de par√¢metros** reduz overfitting
> 5. **Transla√ß√£o invariante** detecta objetos independente da posi√ß√£o

> [!quote] Impacto das CNNs "As CNNs n√£o apenas revolucionaram a vis√£o computacional, mas abriram caminho para aplica√ß√µes de IA que pareciam fic√ß√£o cient√≠fica h√° duas d√©cadas. Desde diagn√≥sticos m√©dicos at√© carros aut√¥nomos, elas s√£o a espinha dorsal da revolu√ß√£o visual da intelig√™ncia artificial."

> [!info] Pr√≥ximos Passos Para aprofundar seus conhecimentos:
> 
> - Experimente com diferentes arquiteturas (ResNet, DenseNet, EfficientNet)
> - Aprenda sobre **Transfer Learning** para problemas reais
> - Explore **GANs** para gera√ß√£o de imagens
> - Estude **Object Detection** (YOLO, R-CNN)
> - Pratique com datasets reais (ImageNet, COCO, CIFAR)
# üìö Guia de Arquiteturas CNN

> [!info] O que √© este guia?
> Este documento re√∫ne as principais arquiteturas de Redes Neurais Convolucionais (CNNs), divididas por categoria, com informa√ß√µes sobre ano, objetivo e disponibilidade no **Keras** e **PyTorch**.  
> Cada nome est√° linkado para um note pr√≥prio.

---

## üìú Arquiteturas Cl√°ssicas
> [!abstract]
> S√£o as redes que marcaram √©poca e serviram de base para modelos mais avan√ßados.

| Arquitetura | Ano | Objetivo Principal | Keras | PyTorch |
|-------------|-----|--------------------|-------|---------|
| [[LeNet-5]] | 1998 | Reconhecimento de d√≠gitos (MNIST) | ‚úÖ | ‚úÖ |
| [[AlexNet]] | 2012 | Classifica√ß√£o ImageNet | ‚úÖ | ‚úÖ |
| [[ZFNet]] | 2013 | Melhorar filtros e visualiza√ß√£o | ‚ùå | ‚úÖ |
| [[VGGNet]] | 2014 | CNN profunda com conv 3√ó3 | ‚úÖ | ‚úÖ |
| [[GoogLeNet / Inception v1]] | 2014 | M√≥dulos multi-escala | ‚úÖ | ‚úÖ |
| [[Inception v2]] / [[Inception v3]] / [[Inception v4]] | 2015‚Äì2016 | Refinamento Inception | ‚úÖ | ‚úÖ |
| [[ResNet]] | 2015 | Conex√µes residuais | ‚úÖ | ‚úÖ |
| [[ResNeXt]] | 2016 | Vers√£o paralela do ResNet | ‚ùå | ‚úÖ |
| [[DenseNet]] | 2017 | Conex√µes densas | ‚úÖ | ‚úÖ |
| [[Xception]] | 2017 | Convolu√ß√µes separ√°veis em profundidade | ‚úÖ | ‚úÖ |
| [[ConvNeXt]] | 2022 | CNN moderna inspirada em Transformers | ‚ùå | ‚úÖ |

---

## üéØ Arquiteturas para Detec√ß√£o
> [!tip]
> Usadas para identificar e localizar objetos em imagens.

| Arquitetura | Ano | Objetivo Principal | Keras | PyTorch |
|-------------|-----|--------------------|-------|---------|
| [[R-CNN]] | 2014 | Detec√ß√£o baseada em regi√µes | ‚ùå | ‚úÖ |
| [[Fast R-CNN]] | 2015 | Detec√ß√£o mais r√°pida | ‚ùå | ‚úÖ |
| [[Faster R-CNN]] | 2015 | ROIs + CNN integrada | ‚ùå | ‚úÖ |
| [[YOLO v1]]‚Äì[[YOLO v9]] | 2016‚Äì2024 | Detec√ß√£o em tempo real | ‚ùå | ‚úÖ |
| [[SSD]] | 2016 | Detec√ß√£o multi-escala | ‚ùå | ‚úÖ |
| [[RetinaNet]] | 2017 | Focal Loss para classes raras | ‚ùå | ‚úÖ |
| [[DETR]] | 2020 | Detec√ß√£o via Transformer | ‚ùå | ‚úÖ |

---

## ü©ª Arquiteturas para Segmenta√ß√£o
> [!example]
> Segmenta√ß√£o √© o processo de rotular cada pixel da imagem com a classe correspondente.

| Arquitetura | Ano | Objetivo Principal | Keras | PyTorch |
|-------------|-----|--------------------|-------|---------|
| [[FCN]] | 2015 | CNN totalmente convolucional | ‚ùå | ‚úÖ |
| [[U-Net]] | 2015 | Segmenta√ß√£o biom√©dica | ‚úÖ | ‚úÖ |
| [[SegNet]] | 2015 | Encoder-decoder com pooling indices | ‚ùå | ‚úÖ |
| [[DeepLab v1]] / [[DeepLab v2]] / [[DeepLab v3+]] | 2016‚Äì2018 | Dilated conv + CRF | ‚ùå | ‚úÖ |
| [[Mask R-CNN]] | 2017 | Detec√ß√£o + Segmenta√ß√£o de inst√¢ncias | ‚ùå | ‚úÖ |

---

## üì± Arquiteturas Leves / Especiais
> [!tip]
> Voltadas para dispositivos m√≥veis, otimiza√ß√£o ou propostas inovadoras.

| Arquitetura | Ano | Objetivo Principal | Keras | PyTorch |
|-------------|-----|--------------------|-------|---------|
| [[SqueezeNet]] | 2016 | Modelo pequeno | ‚ùå | ‚úÖ |
| [[MobileNet v1]] / [[MobileNet v2]] / [[MobileNet v3]] | 2017‚Äì2019 | Dispositivos m√≥veis | ‚úÖ | ‚úÖ |
| [[ShuffleNet]] | 2017 | Efici√™ncia por embaralhar canais | ‚ùå | ‚úÖ |
| [[NASNet]] | 2017 | Busca neural automatizada | ‚úÖ | ‚úÖ |
| [[MnasNet]] | 2018 | Arquitetura via AutoML | ‚ùå | ‚úÖ |
| [[EfficientNet]] | 2019 | Escalonamento √≥timo | ‚úÖ | ‚úÖ |
| [[RegNet]] | 2020 | Redes com regulariza√ß√£o sistem√°tica | ‚ùå | ‚úÖ |
| [[CapsNet]] | 2017 | Redes de c√°psulas | ‚ùå | ‚úÖ |

---

## üîç Como usar este guia
> [!important]
> - Clique no nome da arquitetura para abrir o note espec√≠fico.
> - Prefira modelos **mais leves** se for rodar em celular ou IoT.
> - Modelos de **detec√ß√£o** e **segmenta√ß√£o** podem ser adaptados para m√∫ltiplas tarefas.

---

## üìå Pr√≥ximos Passos
> [!todo]
> - [ ] Criar notas individuais para cada arquitetura com detalhes, diagrama e c√≥digo.  
> - [ ] Expandir o guia para incluir **+40 arquiteturas** intermedi√°rias.  
> - [ ] Criar linha do tempo visual com evolu√ß√£o das CNNs.
