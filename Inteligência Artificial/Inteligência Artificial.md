##  Vis√£o Geral

> [!abstract] A Intelig√™ncia Artificial √© o campo da computa√ß√£o que busca criar sistemas capazes de realizar tarefas que normalmente requerem intelig√™ncia humana. Abrange desde algoritmos cl√°ssicos at√© modelos modernos como Large Language Models.

---
# Componentes do Aprendizado de m√°quina

> [!note] Esses componente s√£o essenciais para "ensinar" uma m√°quina a detectar padr√µes
## Dados

> [!note] Dados comparativos, como voc√™ ter uma amostra de imagens de um certo objetivo para identificar tal objeto.

> [!example] uma amostra de mensagens de span para detectar um spam

> [!attention] Quanto mais diversos os materiais, melhor o resultado.

> [!note] Existem duas formas de termos os dados:
 > - **Manual**: Dados coletados manualmente. Tem menos erros por√©m leva mais tempo para coletar (+ CARO)
 >- **Autom√°tica**: Re√∫ne tudo que pode encontrar e torce pelo melhor.
 
> [!example] O recaptcha √© basicamente vc fornecendo dados para o google para aprendizado.

> [!note] Os conjuntos de dados bons √© bem dif√≠cil de obter, tanto que as empresas raramente revelam eles.

## Caracter√≠sticas

> [!note] Conhecidas tamb√©m como **Par√¢metros** ou **vari√°veis**, √© o que a m√°quina ir√° analisar em si, como se fosse uma coluna de um certo dado em uma tabela. Elas tentam consideras as que elas acham "mais importantes".

> [!warning] Al√©m de ser as partes importantes, s√£o as principais fonte de erros. MeatBug s√£o sempre subjetivos. Normalmente essa parte pe a mais demorada entre as outras do ML

## Algoritmos

> [!note] TEM QUE OBVIAMENTE TER NESSA POHA, se n√£o seria de fuder. 
> 
> Um certo problema pode ser resolvido de v√°rias maneiras, por√©m certo fatores ser√£o modificados dependendo do m√©todo, como:
>  - Desepenho
>  - Tamanho do modelo final
>  - Presi√ß√£o

> [!warning] Se os dados forem uma merda, nem adiante fazer um √≥timo algoritmo. Esse fen√¥meno √© chamado de "Lixo que entra, Lixo que sai"


![[Pasted image 20250810160914.png]]

# Aprendizado VS Intelig√™ncia

## Intelig√™ncia Artificial
> [!abstract] √© o nome de todo um campo do conhecimento, semelhante √† biologia ou √† qu√≠mica

## Aprendizado de m√°quina
> [!abstract] faz parte da intelig√™ncia artificial. Uma parte importante, mas n√£o a √∫nica.

## Redes Neurais
> [!abstract]¬†s√£o um tipo de aprendizado de m√°quina. Um tipo popular, mas existem outros bons no g√™nero.

## Deep Learning
> [!abstract] M√©todos modernos de constru√ß√£o, treinamento e use e redes neurais, uma arquitetura nova.


![[Pasted image 20250810161445.png]]

| ***M√°quina pode***        | ***A m√°quina n√£o pode***           |
| ------------------------- | ---------------------------------- |
| **Previs√£o**              | **Crie algo novo**                 |
| **Memorizar**             | **Fique inteligente muito r√°pido** |
| **Reproduzir**            | **V√° al√©m da sua tarefa**          |
| **Escolha o melhor item** | **Mate todos os humanos**          |
## üìö Taxonomia de Aprendizado de M√°quina

![[Pasted image 20250810161930.png]]

![[Pasted image 20250810162005.png]]

![[Pasted image 20250810162025.png]]

> [!info] Voc√™ pode categorizar os m√©todos de aprendizado com base em algumas categorias como:
> 
>  - Se √© visto por humanos ou n√£o ([[ML - Aprendizado Supervisionado]], [[ML - Aprendizado por Refor√ßo]], [[ML - Aprendizado N√£o-Supervisionado]], [[ML - Aprendizado Semi Supervisionado]])
>  - Se ele aprende de forma incremental online
>  - Se eles funcionam comparando novos pontos de dados com pontos de dados conhecidos, detecte padr√µes nos dados de treinamento e construa um modelo preditivo. 

### [[ML - Aprendizado Supervisionado]]

**Defini√ß√£o:** Algoritmos que aprendem a partir de dados rotulados (X, y)

**Caracter√≠sticas:**

- Possui dados de entrada (features) e sa√≠da esperada (target)
- Objetivo: mapear fun√ß√£o f(X) ‚Üí y
- Avalia√ß√£o atrav√©s de m√©tricas de erro

**Subcategorias:**

- [[ML - Classifica√ß√£o]] ‚Üí Predi√ß√£o de categorias/classes
- [[ML - Regress√£o Linear]] ‚Üí Predi√ß√£o de valores cont√≠nuos

### [[ML - Aprendizado N√£o-Supervisionado]]

**Defini√ß√£o:** Algoritmos que encontram padr√µes em dados sem r√≥tulos

**Caracter√≠sticas:**

- Apenas dados de entrada (X), sem target
- Objetivo: descobrir estruturas ocultas nos dados
- Avalia√ß√£o mais subjetiva

**Subcategorias:**

- [[ML - Clustering]] ‚Üí Agrupamento de dados similares
- [[ML - Redu√ß√£o de Dimensionalidade]] ‚Üí Compress√£o de features
- [[ML - Detec√ß√£o de Anomalias]] ‚Üí Identifica√ß√£o de outliers
- [[ML - Regras de Associa√ß√£o]] ‚Üí Padr√µes de co-ocorr√™ncia


### [[ML - Aprendizado Semi Supervisionado]]

**Defini√ß√£o:** Algoritmos que aprendem a partir de um conjunto misto de dados rotulados e n√£o rotulados.

**Caracter√≠sticas:**

- Combina dados de entrada (X) com alguns r√≥tulos (Y), por√©m com quantidade limitada.
- Objetivo: aproveitar a grande massa de dados n√£o rotulados para melhorar a performance.
- Equilibra a rigidez do aprendizado supervisionado e a flexibilidade do n√£o supervisionado.
- Avalia√ß√£o mais robusta que no n√£o supervisionado, por√©m menos custosa que no supervisionado.

**Abordagens Comuns:**

- Propaga√ß√£o de r√≥tulos (Label Propagation): dissemina informa√ß√µes dos poucos exemplos rotulados para os demais.
- Autoencoders Semi Supervisionados: modelos que aprendem representa√ß√µes √∫teis combinando aprendizado supervisionado e n√£o supervisionado.
- M√©todos baseados em grafos: exploram a estrutura dos dados para inferir r√≥tulos.
- Algoritmos h√≠bridos que combinam aprendizado supervisionado e n√£o supervisionado.

### [[ML - Aprendizado por Refor√ßo]]

**Defini√ß√£o:** Algoritmos que aprendem atrav√©s de intera√ß√£o com ambiente

**Caracter√≠sticas:**

- Agente toma a√ß√µes em um ambiente
- Recebe recompensas/puni√ß√µes
- Objetivo: maximizar recompensa cumulativa

**Subcategorias:**

- [[RL - Q-Learning]] ‚Üí Aprendizado de valores de a√ß√£o
- [[RL - Policy Gradient]] ‚Üí Otimiza√ß√£o direta da pol√≠tica
- [[RL - Actor-Critic]] ‚Üí Combina√ß√£o de valor e pol√≠tica

---

## üìä Matriz de Contextos e Aplica√ß√µes

| **Paradigma**                         | **Problema**                  | **Algoritmos Principais**                                                                                            | **M√©tricas de Avalia√ß√£o**                                                                                                    | **Aplica√ß√µes Reais**                                                                                   |
| ------------------------------------- | ----------------------------- | -------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------ |
| **Supervisionado - Classifica√ß√£o**    | Categorizar dados em classes  | ‚Ä¢ √Årvores de Decis√£o<br>‚Ä¢ Random Forest<br>‚Ä¢ SVM<br>‚Ä¢ [[ML - Naive Bayes]] <br>‚Ä¢ [[Redes Neurais]]                   | ‚Ä¢ Acur√°cia<br>‚Ä¢ Precis√£o/Recall<br>‚Ä¢ F1-Score<br>‚Ä¢ Matriz de Confus√£o<br>‚Ä¢ ROC-AUC                                           | ‚Ä¢ Diagn√≥stico m√©dico<br>‚Ä¢ Spam detection<br>‚Ä¢ Reconhecimento de imagem<br>‚Ä¢ An√°lise de sentimento      |
| **Supervisionado - Regress√£o**        | Predizer valores cont√≠nuos    | ‚Ä¢ [[Regress√£o Linear]]<br>‚Ä¢ [[Regress√£o Log√≠stica]]<br>‚Ä¢ [[SVR]]<br>‚Ä¢ [[Redes Neurais]]<br>‚Ä¢ [[Gradient Boosting]]   | ‚Ä¢ MAE - Mean Absolute Error<br>‚Ä¢ MSE - Mean Squared Error<br>‚Ä¢ RMSE<br>‚Ä¢ [[R¬≤ Score]]<br>‚Ä¢ [[MAPE]]                          | ‚Ä¢ Previs√£o de pre√ßos<br>‚Ä¢ Estimativa de vendas<br>‚Ä¢ Previs√£o do tempo<br>‚Ä¢ An√°lise financeira          |
| **N√£o-Supervisionado - Clustering**   | Agrupar dados similares       | ‚Ä¢ [[K-Means]]<br>‚Ä¢ [[Clustering Hier√°rquico]]<br>‚Ä¢ [[DBSCAN]]<br>‚Ä¢ [[Gaussian Mixture]]<br>‚Ä¢ [[Spectral Clustering]] | ‚Ä¢ [[Silhouette Score]]<br>‚Ä¢ [[Calinski-Harabasz]]<br>‚Ä¢ [[Davies-Bouldin]]<br>‚Ä¢ [[Inertia/WCSS]]<br>‚Ä¢ [[Adjusted Rand Index]] | ‚Ä¢ Segmenta√ß√£o de clientes<br>‚Ä¢ An√°lise de mercado<br>‚Ä¢ Organiza√ß√£o de documentos<br>‚Ä¢ An√°lise gen√©tica |
| **N√£o-Supervisionado - Redu√ß√£o Dim.** | Reduzir complexidade          | ‚Ä¢ [[PCA]]<br>‚Ä¢ [[t-SNE]]<br>‚Ä¢ [[UMAP]]<br>‚Ä¢ [[LDA]]<br>‚Ä¢ [[Autoencoders]]                                            | ‚Ä¢ [[Vari√¢ncia Explicada]]<br>‚Ä¢ [[Reconstruction Error]]<br>‚Ä¢ [[Stress (t-SNE)]]<br>‚Ä¢ [[Trustworthiness]]<br>‚Ä¢ [[Continuity]] | ‚Ä¢ Visualiza√ß√£o de dados<br>‚Ä¢ Compress√£o<br>‚Ä¢ Pr√©-processamento<br>‚Ä¢ Feature engineering                |
| **Aprendizado por Refor√ßo**           | Otimizar decis√µes sequenciais | ‚Ä¢ [[Q-Learning]]<br>‚Ä¢ [[Deep Q-Network]]<br>‚Ä¢ [[Policy Gradient]]<br>‚Ä¢ [[Actor-Critic]]<br>‚Ä¢ [[PPO]]                 | ‚Ä¢ [[Reward Cumulativo]]<br>‚Ä¢ [[Episode Length]]<br>‚Ä¢ [[Success Rate]]<br>‚Ä¢ [[Convergence Time]]<br>‚Ä¢ [[Sample Efficiency]]   | ‚Ä¢ Jogos (AlphaGo)<br>‚Ä¢ Carros aut√¥nomos<br>‚Ä¢ Trading algor√≠tmico<br>‚Ä¢ Rob√≥tica                         |

---

## üß† Deep Learning e Arquiteturas Neurais

### [[Deep Learning - Redes Neurais Profundas]]

#### **Arquiteturas Fundamentais:**

|**Tipo de Rede**|**Estrutura**|**Aplica√ß√µes**|**Vantagens**|**Limita√ß√µes**|
|---|---|---|---|---|
|**[[MLP - Multi-Layer Perceptron]]**|Camadas densas conectadas|‚Ä¢ Classifica√ß√£o tabular<br>‚Ä¢ Regress√£o<br>‚Ä¢ Aproxima√ß√£o de fun√ß√µes|‚Ä¢ Simples implementa√ß√£o<br>‚Ä¢ Universal approximator<br>‚Ä¢ Bem estabelecido|‚Ä¢ N√£o captura padr√µes espaciais<br>‚Ä¢ Muitos par√¢metros<br>‚Ä¢ Overfitting|
|**[[CNN - Convolutional Neural Networks]]**|Convolu√ß√µes + Pooling|‚Ä¢ Vis√£o computacional<br>‚Ä¢ Reconhecimento de imagem<br>‚Ä¢ Processamento de sinais|‚Ä¢ Translation invariant<br>‚Ä¢ Menos par√¢metros<br>‚Ä¢ Hierarquia de features|‚Ä¢ Requer dados estruturados<br>‚Ä¢ Computacionalmente intensivo|
|**[[RNN - Recurrent Neural Networks]]**|Conex√µes recorrentes|‚Ä¢ Processamento de sequ√™ncias<br>‚Ä¢ S√©ries temporais<br>‚Ä¢ NLP b√°sico|‚Ä¢ Mem√≥ria temporal<br>‚Ä¢ Tamanho vari√°vel<br>‚Ä¢ Compartilha par√¢metros|‚Ä¢ Vanishing gradient<br>‚Ä¢ Dificuldade com long-range|
|**[[LSTM - Long Short-Term Memory]]**|Gates de mem√≥ria|‚Ä¢ S√©ries temporais longas<br>‚Ä¢ Tradu√ß√£o autom√°tica<br>‚Ä¢ An√°lise de texto|‚Ä¢ Resolve vanishing gradient<br>‚Ä¢ Mem√≥ria seletiva<br>‚Ä¢ Sequ√™ncias longas|‚Ä¢ Complexidade computacional<br>‚Ä¢ Muitos hiperpar√¢metros|
|**[[Transformer]]**|Attention mechanism|‚Ä¢ NLP avan√ßado<br>‚Ä¢ Tradu√ß√£o<br>‚Ä¢ Gera√ß√£o de texto|‚Ä¢ Paraleliza√ß√£o<br>‚Ä¢ Long-range dependencies<br>‚Ä¢ Transfer learning|‚Ä¢ Requer muitos dados<br>‚Ä¢ Computacionalmente caro|

---

## ü§ñ Large Language Models (LLMs)

### [[LLM - Fundamentos]]

**Defini√ß√£o:** Modelos de linguagem de grande escala treinados em vastos corpora textuais para entender e gerar linguagem natural.

#### **Evolu√ß√£o Hist√≥rica:**

```mermaid
timeline
    title Evolu√ß√£o dos LLMs
    2017 : Transformer Architecture
         : "Attention is All You Need"
    2018 : BERT
         : Bidirectional Encoder
    2019 : GPT-2
         : 1.5B par√¢metros
    2020 : GPT-3
         : 175B par√¢metros
    2021 : PaLM
         : 540B par√¢metros
    2022 : ChatGPT
         : RLHF + GPT-3.5
    2023 : GPT-4
         : Multimodal
    2024 : Claude-4
         : Constitutional AI
```

#### **Taxonomia de LLMs:**

|**Categoria**|**Modelos**|**Par√¢metros**|**Caracter√≠sticas**|**Casos de Uso**|
|---|---|---|---|---|
|**[[LLM - Base Models]]**|‚Ä¢ GPT-3/4<br>‚Ä¢ PaLM<br>‚Ä¢ LLaMA<br>‚Ä¢ Claude|7B - 540B+|‚Ä¢ Pr√©-treinados<br>‚Ä¢ Prop√≥sito geral<br>‚Ä¢ Foundation models|‚Ä¢ Fine-tuning<br>‚Ä¢ Research<br>‚Ä¢ Base para especializa√ß√£o|
|**[[LLM - Chat Models]]**|‚Ä¢ ChatGPT<br>‚Ä¢ Claude<br>‚Ä¢ Bard<br>‚Ä¢ LLaMA-Chat|Variado|‚Ä¢ RLHF aplicado<br>‚Ä¢ Conversacional<br>‚Ä¢ Aligned|‚Ä¢ Assistentes virtuais<br>‚Ä¢ Chatbots<br>‚Ä¢ Suporte ao cliente|
|**[[LLM - Code Models]]**|‚Ä¢ Codex<br>‚Ä¢ GitHub Copilot<br>‚Ä¢ CodeT5<br>‚Ä¢ StarCoder|1B - 175B|‚Ä¢ Treinado em c√≥digo<br>‚Ä¢ Multi-linguagem<br>‚Ä¢ Code completion|‚Ä¢ Programa√ß√£o assistida<br>‚Ä¢ Code generation<br>‚Ä¢ Debug|
|**[[LLM - Multimodal]]**|‚Ä¢ GPT-4V<br>‚Ä¢ DALL-E<br>‚Ä¢ Flamingo<br>‚Ä¢ CLIP|Variado|‚Ä¢ Texto + imagem<br>‚Ä¢ Cross-modal<br>‚Ä¢ Vision-language|‚Ä¢ Gera√ß√£o de imagens<br>‚Ä¢ Visual Q&A<br>‚Ä¢ Content creation|
|**[[LLM - Domain-Specific]]**|‚Ä¢ BioBERT<br>‚Ä¢ FinBERT<br>‚Ä¢ LegalBERT<br>‚Ä¢ SciBERT|100M - 1B|‚Ä¢ Fine-tuned<br>‚Ä¢ Especializado<br>‚Ä¢ Domain knowledge|‚Ä¢ Medicina<br>‚Ä¢ Finan√ßas<br>‚Ä¢ Direito<br>‚Ä¢ Ci√™ncia|

### [[LLM - T√©cnicas de Treinamento]]

#### **Pipeline de Desenvolvimento:**

1. **[[Pre-training]]**
    
    - Dados: Crawl da internet, livros, artigos
    - Objetivo: Predi√ß√£o do pr√≥ximo token
    - Escala: Trilh√µes de tokens
2. **[[Fine-tuning]]**
    
    - Supervised Fine-tuning (SFT)
    - Task-specific adaptation
    - Domain adaptation
3. **[[RLHF - Reinforcement Learning from Human Feedback]]**
    
    - Human preference data
    - Reward modeling
    - Policy optimization (PPO)
4. **[[Constitutional AI]]**
    
    - Self-supervision
    - Principle-based training
    - Harmlessness optimization

---

## üìè M√©tricas de Avalia√ß√£o Detalhadas

### [[M√©tricas - Classifica√ß√£o]]

#### **Matriz de Confus√£o:**

```
           Predito
         0    1
Real  0 [TN] [FP]
      1 [FN] [TP]
```

**M√©tricas Derivadas:**

- **[[Acur√°cia]]**: (TP + TN) / (TP + TN + FP + FN)
- **[[Precis√£o]]**: TP / (TP + FP)
- **[[Recall/Sensibilidade]]**: TP / (TP + FN)
- **[[Especificidade]]**: TN / (TN + FP)
- **[[F1-Score]]**: 2 √ó (Precis√£o √ó Recall) / (Precis√£o + Recall)

#### **M√©tricas Avan√ßadas:**

- **[[ROC-AUC]]**: Area Under ROC Curve
- **[[PR-AUC]]**: Area Under Precision-Recall Curve
- **[[Matthews Correlation Coefficient]]**: MCC
- **[[Cohen's Kappa]]**: Inter-rater agreement

### [[M√©tricas - Regress√£o]]

- **[[MAE]]**: Mean Absolute Error
- **[[MSE]]**: Mean Squared Error
- **[[RMSE]]**: Root Mean Squared Error
- **[[MAPE]]**: Mean Absolute Percentage Error
- **[[R¬≤ Score]]**: Coefficient of Determination

### [[M√©tricas - NLP e LLMs]]

- **[[BLEU Score]]**: Machine Translation
- **[[ROUGE Score]]**: Text Summarization
- **[[METEOR]]**: Machine Translation
- **[[BERTScore]]**: Semantic similarity
- **[[Perplexity]]**: Language model quality

---

## üîß Ferramentas e Frameworks

### [[ML - Bibliotecas Cl√°ssicas]]

```python
# Scikit-learn - ML tradicional
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report

# Pandas - Manipula√ß√£o de dados
import pandas as pd

# NumPy - Computa√ß√£o num√©rica
import numpy as np
```

### [[Deep Learning - Frameworks]]

```python
# TensorFlow/Keras
import tensorflow as tf
from tensorflow.keras.models import Sequential

# PyTorch
import torch
import torch.nn as nn

# Hugging Face - Transformers
from transformers import AutoModel, AutoTokenizer
```

### [[LLM - APIs e Interfaces]]

```python
# OpenAI API
import openai

# Anthropic Claude
import anthropic

# Local models
from transformers import pipeline
```

---

## üéØ Projetos Pr√°ticos por Categoria

### **Supervisionado - Classifica√ß√£o**

- [ ] [[Projeto - Classifica√ß√£o de Emails (Spam/Ham)]]
- [ ] [[Projeto - Diagn√≥stico M√©dico com ML]]
- [ ] [[Projeto - Reconhecimento de D√≠gitos com CNN]]

### **Supervisionado - Regress√£o**

- [ ] [[Projeto - Predi√ß√£o de Pre√ßos Imobili√°rios]]
- [ ] [[Projeto - Previs√£o de Vendas com Time Series]]
- [ ] [[Projeto - Estimativa de Consumo Energ√©tico]]

### **N√£o-Supervisionado**

- [ ] [[Projeto - Segmenta√ß√£o de Clientes com K-Means]]
- [ ] [[Projeto - Sistema de Recomenda√ß√£o]]
- [ ] [[Projeto - Detec√ß√£o de Fraudes]]

### **Deep Learning**

- [ ] [[Projeto - Classifica√ß√£o de Imagens com CNN]]
- [ ] [[Projeto - An√°lise de Sentimentos com LSTM]]
- [ ] [[Projeto - Chatbot com Transformers]]

### **LLMs**

- [ ] [[Projeto - Fine-tuning de LLM para Dom√≠nio Espec√≠fico]]
- [ ] [[Projeto - Sistema RAG (Retrieval-Augmented Generation)]]
- [ ] [[Projeto - Code Assistant com LLM]]

---

## üó∫Ô∏è Roadmap de Estudos

### **Fase 1: Fundamentos (Semanas 1-4)**

- [ ] [[ML - Conceitos B√°sicos]]
- [ ] [[Estat√≠stica para ML]]
- [ ] [[Python para Data Science]]
- [ ] [[Pandas e NumPy]]

### **Fase 2: ML Cl√°ssico (Semanas 5-8)**

- [ ] [[Supervisionado - Classifica√ß√£o]]
- [ ] [[Supervisionado - Regress√£o]]
- [ ] [[Valida√ß√£o Cruzada e M√©tricas]]
- [ ] [[Feature Engineering]]

### **Fase 3: ML Avan√ßado (Semanas 9-12)**

- [ ] [[Ensemble Methods]]
- [ ] [[N√£o-Supervisionado]]
- [ ] [[Aprendizado por Refor√ßo B√°sico]]
- [ ] [[Hyperparameter Tuning]]

### **Fase 4: Deep Learning (Semanas 13-16)**

- [ ] [[Redes Neurais B√°sicas]]
- [ ] [[CNN para Vis√£o Computacional]]
- [ ] [[RNN/LSTM para Sequ√™ncias]]
- [ ] [[Transfer Learning]]

### **Fase 5: NLP e Transformers (Semanas 17-20)**

- [ ] [[Processamento de Linguagem Natural]]
- [ ] [[Word Embeddings]]
- [ ] [[Transformer Architecture]]
- [ ] [[BERT e GPT]]

### **Fase 6: LLMs Modernos (Semanas 21-24)**

- [ ] [[Large Language Models]]
- [ ] [[Prompt Engineering]]
- [ ] [[Fine-tuning Techniques]]
- [ ] [[RAG e Vector Databases]]

---

## üîó Conex√µes com Outras Disciplinas

### **Pr√©-requisitos**

- [[Estat√≠stica e Probabilidade]]
- [[√Ålgebra Linear]]
- [[C√°lculo Diferencial]]
- [[Programa√ß√£o Orientada a Objetos]]

### **Disciplinas Relacionadas**

- [[Banco de Dados]] ‚Üí Data storage para ML
- [[Sistemas Distribu√≠dos]] ‚Üí ML em larga escala
- [[Compiladores]] ‚Üí Otimiza√ß√£o de modelos
- [[Redes de Computadores]] ‚Üí Distributed training

### **Aplica√ß√µes Interdisciplinares**

- [[Bioinform√°tica]] ‚Üí ML para gen√¥mica
- [[Finan√ßas Quantitativas]] ‚Üí Trading algorithms
- [[Medicina]] ‚Üí Diagn√≥stico assistido
- [[Rob√≥tica]] ‚Üí Controle inteligente

---


### **Certifica√ß√µes Obtidas:**

- [ ] [[Certifica√ß√£o - Machine Learning Stanford (Coursera)]]
- [ ] [[Certifica√ß√£o - Deep Learning Specialization]]
- [ ] [[Certifica√ß√£o - TensorFlow Developer]]
- [ ] [[Certifica√ß√£o - AWS Machine Learning]]

---

## üé≤ Casos de Estudo Famosos

### **ML Cl√°ssico**

- [[Case - Netflix Prize (Recommendation Systems)]]
- [[Case - Kaggle Titanic (Classification)]]
- [[Case - Boston Housing (Regression)]]

### **Deep Learning**

- [[Case - ImageNet Challenge (CNN)]]
- [[Case - AlphaGo (Reinforcement Learning)]]
- [[Case - Neural Machine Translation]]

### **LLMs**

- [[Case - GPT-3 Emergence]]
- [[Case - ChatGPT Adoption]]
- [[Case - GitHub Copilot Impact]]

---

## üè∑Ô∏è Tags Especializadas

#machine-learning #deep-learning #llm #gpt #bert #transformer #cnn #rnn #lstm #reinforcement-learning #supervised-learning #unsupervised-learning #classification #regression #clustering #nlp #computer-vision #neural-networks #pytorch #tensorflow #scikit-learn #huggingface #openai #anthropic #fine-tuning #rlhf #rag #prompt-engineering

**√öltima Atualiza√ß√£o:** [Data Atual] **Pr√≥xima Revis√£o:** [Data + 1 semana]