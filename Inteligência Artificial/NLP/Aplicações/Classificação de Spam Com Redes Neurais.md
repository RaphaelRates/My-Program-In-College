Entendi! Vou reorganizar como blocos explicativos no estilo Obsidian:

---

# ğŸ§  **ImportaÃ§Ã£o de Bibliotecas**

```python
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.metrics import confusion_matrix, accuracy_score, classification_report
from keras.models import Sequential
from keras.layers import Dense, Dropout
from google.colab import files
```

> [!seealso] ğŸ“¦ **O que este bloco faz:**
> - Importa todas as ferramentas necessÃ¡rias
> - `pandas`: para manipular dados tabulares
> - `sklearn`: para prÃ©-processamento e mÃ©tricas
> - `keras`: para construir a rede neural
> - `google.colab`: para upload de arquivos

---

# ğŸ“– **Leitura e ExploraÃ§Ã£o dos Dados**

```python
spam = pd.read_csv("spam.csv")
spam.head()
spam.shape
spam['Category'].value_counts()
```

> [!seealso] ğŸ” **Objetivo deste bloco:**
> - Carrega o dataset de spam
> - Mostra as primeiras linhas para inspeÃ§Ã£o
> - Verifica o formato (quantidade de linhas e colunas)
> - Conta quantas mensagens sÃ£o spam vs ham
> 
> **SaÃ­da esperada:** VerificaÃ§Ã£o inicial da qualidade dos dados

---

# ğŸ”§ **PrÃ©-processamento dos Dados**

```python
labelEncoder = LabelEncoder()
y = labelEncoder.fit_transform(spam['Category'])

vectorizer = CountVectorizer()
X = vectorizer.fit_transform(spam['Message'])
print(X.shape)
```

> [!seealso]  âš™ï¸ **TransformaÃ§Ãµes aplicadas:**
> - **LabelEncoder**: Converte labels textuais ("spam", "ham") em nÃºmeros (1, 0)
> - **CountVectorizer**: Transforma o texto das mensagens em vetores numÃ©ricos
> - Cada palavra vira uma feature (coluna) na matriz
> 
> **Resultado:** Dados prontos para alimentar a rede neural

---

# ğŸ¯ **DivisÃ£o Treino/Teste**

```python
X_treinamento, X_teste, y_treinamento, y_teste = train_test_split(
    X, y, test_size=0.3, random_state=42
)
```

> [!seealso] ğŸ“Š **EstratÃ©gia de validaÃ§Ã£o:**
> - Separa 70% dos dados para treino
> - Reserva 30% para teste
> - `random_state=42` garante reproducibilidade
> - Evita overfitting ao testar em dados nÃ£o vistos

---

# ğŸ§  **ConstruÃ§Ã£o da Rede Neural**

```python
modelo = Sequential()
modelo.add(Dense(128, input_shape=(X.shape[1],), activation='relu'))
modelo.add(Dropout(0.3))
modelo.add(Dense(64, activation='relu'))
modelo.add(Dropout(0.3))
modelo.add(Dense(1, activation='sigmoid'))

modelo.compile(
    loss='binary_crossentropy',
    optimizer='adam',
    metrics=['accuracy']
)
```

> [!seealso] ğŸ—ï¸ **Arquitetura da rede:**
> - **Camada entrada**: 128 neurÃ´nios + ReLU
> - **Dropout 30%**: Previne overfitting
> - **Camada oculta**: 64 neurÃ´nios + ReLU  
> - **Dropout 30%**: RegularizaÃ§Ã£o adicional
> - **Camada saÃ­da**: 1 neurÃ´nio + sigmoid (binÃ¡ria)
> - **CompilaÃ§Ã£o**: Otimizador Adam + binary_crossentropy

---

# ğŸ‹ï¸ **Treinamento do Modelo**

```python
modelo.fit(
    X_treinamento.toarray(), 
    y_treinamento, 
    epochs=10, 
    batch_size=32, 
    validation_data=(X_teste.toarray(), y_teste)
)
```

> [!abstract] ğŸ¯ **Processo de aprendizado:**
> - **epochs=10**: 10 passadas completas pelos dados
> - **batch_size=32**: Processa 32 amostras por vez
> - **validation_data**: Monitora performance em tempo real
> - **.toarray()**: Converte matriz esparsa para densa (requisito do Keras)

---

# ğŸ“Š **AvaliaÃ§Ã£o do Modelo**

```python
previsoes = (modelo.predict(X_teste.toarray()) > 0.5).astype("int32")

print("AcurÃ¡cia:", accuracy_score(y_teste, previsoes))
print("Matriz de confusÃ£o:\n", confusion_matrix(y_teste, previsoes))
print("RelatÃ³rio:\n", classification_report(y_teste, previsoes))
```

> [!abstract] ğŸ“ˆ **MÃ©tricas de performance:**
> - **AcurÃ¡cia**: Porcentagem de acertos totais
> - **Matriz de confusÃ£o**: Verdadeiros vs falsos positivos/negativos
> - **RelatÃ³rio**: PrecisÃ£o, recall e F1-score por classe
> - **Threshold 0.5**: Converte probabilidades em classes binÃ¡rias

---

# ğŸ” **Teste com Novas Mensagens**

```python
def classificar_mensagem(mensagem):
    mensagem_vetorizada = vectorizer.transform([mensagem])
    probabilidade = modelo.predict(mensagem_vetorizada.toarray())[0][0]
    return "spam" if probabilidade > 0.5 else "ham", probabilidade
```

> [!tip] ğŸ§ª **AplicaÃ§Ã£o prÃ¡tica:**
> - FunÃ§Ã£o para classificar novas mensagens em tempo real
> - Reutiliza o vectorizer treinado anteriormente
> - Retorna both a classe e a confianÃ§a da prediÃ§Ã£o
> - Ãštil para deployment em sistemas reais
