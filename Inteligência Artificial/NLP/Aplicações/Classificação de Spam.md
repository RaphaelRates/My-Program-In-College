> [!note] okokok

# Importa√ß√£o de Libs

```python
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn import metrics
from sklearn.metrics import confusion_matrix, accuracy_score
from sklearn.emseble import RandomFlorestClassifier
from sklearn.feature_extraction.text import TfidVectorizer
from google.colab import files
```
 
## **Pandas**

Usado para lidar com **dados tabulares** (planilhas, CSVs, etc). Permite ler, organizar, filtrar e manipular conjuntos de dados de forma eficiente.

Exemplo:

```python
import pandas as pd
df = pd.read_csv('dados.csv')
```

---

## üß† **Scikit-learn (sklearn)**

Biblioteca poderosa para **treinamento e avalia√ß√£o de modelos de IA**.

### üîπ **train_test_split**

Divide o dataset em partes de **treino**, **teste** e, opcionalmente, **valida√ß√£o**.

> Serve pra garantir que o modelo aprenda com uma parte e seja avaliado em outra.

### üîπ **metrics**

Conjunto de **m√©tricas de avalia√ß√£o** (recall, precis√£o, F1, ROC, etc). Usado pra medir qu√£o bem o modelo est√° performando.

### üîπ **confusion_matrix e accuracy_score**

- `confusion_matrix`: mostra quantos acertos e erros o modelo cometeu para cada classe.
    
- `accuracy_score`: mede a **porcentagem total de acertos** do modelo.
    

### üîπ **RandomForestClassifier**

Modelo de **classifica√ß√£o baseado em v√°rias √°rvores de decis√£o**. Cada √°rvore d√° seu voto, e o resultado final √© a maioria ‚Äî tornando o modelo mais robusto e menos propenso a overfitting.

### üîπ **TfidfVectorizer**

Transforma **texto em n√∫meros** usando o m√©todo **TF-IDF (Term Frequency ‚Äì Inverse Document Frequency)**.

> Palavras frequentes em um documento, mas raras no corpus, recebem maior peso ‚Äî representando melhor sua import√¢ncia no contexto.


### üîπ **Colab**

Fun√ß√µes do pr√≥prio editor do cola, que ser√° usado nesse exemplo 

---

## üìä **Resumo r√°pido**

| M√≥dulo                            | Fun√ß√£o principal                    |
| --------------------------------- | ----------------------------------- |
| pandas                            | Manipular dados tabulares           |
| train_test_split                  | Dividir treino/teste                |
| metrics                           | Avaliar desempenho                  |
| confusion_matrix / accuracy_score | M√©tricas espec√≠ficas                |
| RandomForestClassifier            | Modelo de machine learning          |
| TfidfVectorizer                   | Converter texto em vetor num√©rico   |
| Colab                             | Lidar com o Editor de c√≥digo online |

# Leitura do arquivo

> [!abstract] 
> usaremos o Pandas para ler o arquivo **spam.csv** e cria um **DataFrame** chamado `span` com os dados da planilha (geralmente, mensagens e r√≥tulos tipo _spam_ / _ham_). Depois, Mostramos  as **primeiras 5 linhas** do DataFrame, s√≥ pra inspecionar o formato e ver se os dados est√£o ok. 
> 
> Tamb√©m Retornamos o **tamanho da tabela** (linhas, colunas). Exemplo: `(5572, 2)` ‚Üí 5572 mensagens e 2 colunas, e por √∫ltimo, contamos **quantas mensagens h√° em cada categoria**.
> ```python
   span = pd.read_csv("spam.csv")
   span.head()
   span.shape
   span['Category'].value_counts()
> ```
> [!element] **Defini√ß√£o das vari√°veis e vetoriza√ß√£o do texto**
>
> Primeiro, definimos as **mensagens** (entradas) e as **classes** (r√≥tulos):
> 
> ```python
> previ = span['Message']   # textos das mensagens
> classe = span['Category'] # r√≥tulo: 'spam' ou 'ham'
> ```
> 
> Depois criamos o **vetorizador TF-IDF**, que transforma texto em n√∫meros para o modelo poder entender:
> 
> ```python
> from sklearn.feature_extraction.text import TfidfVectorizer
> 
> vetorizador = TfidfVectorizer()
> previsores = vetorizador.fit_transform(previ)
> print(previsores.shape)
> print(vetorizador.get_feature_names_out()[10:100])
> ```
>
> üìä **O que acontece aqui:**
> 
> - `fit_transform(previ)` analisa todas as palavras do dataset (`fit`) e cria uma matriz num√©rica (`transform`);
   >  
> - Cada linha representa uma mensagem;
   >  
> - Cada coluna, uma palavra √∫nica;
>
> - `print(previsores.shape)` mostra o tamanho dessa matriz (ex.: `(5572, 8713)` ‚Üí 5572 mensagens e 8713 palavras √∫nicas).    

> [!element] **Treinamento do modelo Random Forest**
> 
> Agora dividimos os dados entre **treino** e **teste**, e treinamos o modelo.

```python
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier

# Divide os dados (70% treino, 30% teste)
X_treinamento, X_teste, y_treinamento, y_teste = train_test_split(
    previsores, classe, test_size=0.3
)

print(X_teste.shape)
```

Em seguida, criamos o modelo **Random Forest** com 500 √°rvores e treinamos ele nos dados:

```python
floresta = RandomForestClassifier(n_estimators=500)
floresta.fit(X_treinamento, y_treinamento)
```

---

üìä **Explica√ß√£o r√°pida:**

- `train_test_split`: separa os dados em treino e teste pra avaliar o desempenho do modelo.
    
- `RandomForestClassifier`: cria um conjunto de √°rvores de decis√£o.
    
- `n_estimators=500`: define **quantas √°rvores** o modelo vai usar (quanto mais, geralmente mais est√°vel).
    
- `fit(...)`: treina o modelo com os dados de treino.
    

üí° Dica: depois disso, tu pode avaliar o modelo assim:

```python
from sklearn.metrics import accuracy_score, confusion_matrix

previsoes = floresta.predict(X_teste)
print('Acur√°cia:', accuracy_score(y_teste, previsoes))
print('Matriz de confus√£o:\\n', confusion_matrix(y_teste, previsoes))
print(accuracy_score(y_test, previsoes))
print(metrics.classification_report(y_test, previsoes))
```
